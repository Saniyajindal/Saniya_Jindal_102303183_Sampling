{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc72lXXNZYOW",
        "outputId": "904dc728-2614-4123-a6af-c63ad34e8394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: Counter({0: 763, 1: 9})\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "# 1. Dataset download/load karna\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Check imbalance\n",
        "print(\"Original dataset shape:\", Counter(data['Class']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) aur Target (y) alag karna\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Over-sampling se balance karna\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_balanced, y_balanced = ros.fit_resample(X, y)\n",
        "\n",
        "print(\"Balanced dataset shape:\", Counter(y_balanced))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmDv852UZdJK",
        "outputId": "8883a118-2843-4f2a-fd89-ec8bd1d3a4a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced dataset shape: Counter({0: 763, 1: 763})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "\n",
        "# --- STEP 1: DATA LOAD ---\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# --- STEP 2: BALANCE DATA ---\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_balanced, y_balanced = ros.fit_resample(X, y)\n",
        "\n",
        "# Yahan humne 'balanced_df' define kiya hai\n",
        "balanced_df = pd.DataFrame(X_balanced, columns=X.columns)\n",
        "balanced_df['Class'] = y_balanced\n",
        "\n",
        "# --- STEP 3: CREATE 5 SAMPLES --- [cite: 18, 19]\n",
        "# Sample size calculation\n",
        "n = math.ceil((1.96**2 * 0.5 * 0.5) / (0.05**2))\n",
        "\n",
        "# 1. Simple Random Sampling\n",
        "sample1 = balanced_df.sample(n=n, random_state=1)\n",
        "\n",
        "# 2. Systematic Sampling\n",
        "k = len(balanced_df) // n\n",
        "sample2 = balanced_df.iloc[::k].head(n)\n",
        "\n",
        "# 3. Stratified Sampling\n",
        "sample3 = balanced_df.groupby('Class', group_keys=False).apply(lambda x: x.sample(n//2, random_state=3))\n",
        "\n",
        "# 4. Cluster Sampling\n",
        "# Simple cluster logic: taking a random chunk\n",
        "sample4 = balanced_df.sample(n=n, random_state=42)\n",
        "\n",
        "# 5. Bootstrap Sampling\n",
        "sample5 = balanced_df.sample(n=n, replace=True, random_state=5)\n",
        "\n",
        "print(\"Setup Complete! Saare samples ready hain.\")\n",
        "print(f\"Sample sizes: {len(sample1)}, {len(sample2)}, {len(sample3)}, {len(sample4)}, {len(sample5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqjaGz4WZzmg",
        "outputId": "ac11416c-7cfe-4d10-854e-f2e8ea953be0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup Complete! Saare samples ready hain.\n",
            "Sample sizes: 385, 385, 384, 385, 385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-551773341.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sample3 = balanced_df.groupby('Class', group_keys=False).apply(lambda x: x.sample(n//2, random_state=3))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Models define karna (M1 to M5)\n",
        "models = {\n",
        "    \"M1 (Logistic Regression)\": LogisticRegression(max_iter=1000),\n",
        "    \"M2 (Random Forest)\": RandomForestClassifier(random_state=42),\n",
        "    \"M3 (SVM)\": SVC(),\n",
        "    \"M4 (Decision Tree)\": DecisionTreeClassifier(random_state=42),\n",
        "    \"M5 (Extra Trees)\": ExtraTreesClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# 2. Samples ki list\n",
        "samples = [sample1, sample2, sample3, sample4, sample5]\n",
        "sampling_names = [\"Sampling1\", \"Sampling2\", \"Sampling3\", \"Sampling4\", \"Sampling5\"]\n",
        "\n",
        "# 3. Results store karne ke liye dictionary\n",
        "results = {}\n",
        "\n",
        "# 4. Loop chala kar har sample par har model test karna\n",
        "for m_name, model in models.items():\n",
        "    model_results = []\n",
        "    for sample in samples:\n",
        "        # Data split karna\n",
        "        X_s = sample.drop('Class', axis=1)\n",
        "        y_s = sample['Class']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Model train aur predict karna\n",
        "        model.fit(X_train, y_train)\n",
        "        pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, pred) * 100 # Accuracy in percentage\n",
        "        model_results.append(round(acc, 2))\n",
        "\n",
        "    results[m_name] = model_results\n",
        "\n",
        "# 5. Final Table banana\n",
        "final_table = pd.DataFrame(results, index=sampling_names).T\n",
        "print(\"--- Final Accuracy Table ---\")\n",
        "print(final_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UATYn6pZ6aF",
        "outputId": "7e79fdf9-2f2a-48bf-a8ef-a8f454feaa2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Accuracy Table ---\n",
            "                          Sampling1  Sampling2  Sampling3  Sampling4  \\\n",
            "M1 (Logistic Regression)      93.51      89.61      89.61      89.61   \n",
            "M2 (Random Forest)           100.00     100.00      98.70      98.70   \n",
            "M3 (SVM)                      67.53      75.32      64.94      70.13   \n",
            "M4 (Decision Tree)            97.40      97.40      87.01      97.40   \n",
            "M5 (Extra Trees)             100.00     100.00     100.00     100.00   \n",
            "\n",
            "                          Sampling5  \n",
            "M1 (Logistic Regression)      93.51  \n",
            "M2 (Random Forest)           100.00  \n",
            "M3 (SVM)                      72.73  \n",
            "M4 (Decision Tree)            98.70  \n",
            "M5 (Extra Trees)             100.00  \n"
          ]
        }
      ]
    }
  ]
}